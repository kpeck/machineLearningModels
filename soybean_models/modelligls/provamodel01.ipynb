{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.978\n",
      "Model:                            OLS   Adj. R-squared:                  0.976\n",
      "Method:                 Least Squares   F-statistic:                     434.1\n",
      "Date:                Wed, 12 May 2021   Prob (F-statistic):          4.01e-173\n",
      "Time:                        23:26:15   Log-Likelihood:                -1190.5\n",
      "No. Observations:                 250   AIC:                             2429.\n",
      "Df Residuals:                     226   BIC:                             2513.\n",
      "Df Model:                          23                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       1148.4430     24.865     46.187      0.000    1099.446    1197.440\n",
      "x1             1.6981     19.896      0.085      0.932     -37.507      40.904\n",
      "x2             2.4715     19.152      0.129      0.897     -35.268      40.211\n",
      "x3           -97.4634     39.858     -2.445      0.015    -176.004     -18.923\n",
      "x4            85.5740     35.403      2.417      0.016      15.813     155.335\n",
      "x5            64.1065     40.453      1.585      0.114     -15.607     143.820\n",
      "x6           -60.3536     40.026     -1.508      0.133    -139.226      18.518\n",
      "x7             5.0378      7.576      0.665      0.507      -9.890      19.966\n",
      "x8            -6.0341     10.822     -0.558      0.578     -27.358      15.290\n",
      "x9            -0.0416      5.882     -0.007      0.994     -11.633      11.549\n",
      "x10           13.2614      8.047      1.648      0.101      -2.595      29.118\n",
      "x11           -7.3617      8.684     -0.848      0.397     -24.474       9.751\n",
      "x12           14.4970      8.021      1.807      0.072      -1.308      30.302\n",
      "x13           35.2617     15.757      2.238      0.026       4.213      66.311\n",
      "x14           -4.7779      9.276     -0.515      0.607     -23.057      13.501\n",
      "x15          -17.5272      8.078     -2.170      0.031     -33.445      -1.610\n",
      "x16           -8.9938      6.485     -1.387      0.167     -21.772       3.784\n",
      "x17           -3.2279     10.113     -0.319      0.750     -23.155      16.699\n",
      "x18            4.3663      4.045      1.079      0.282      -3.604      12.337\n",
      "x19            1.6273      6.091      0.267      0.790     -10.375      13.629\n",
      "x20           -3.7032      7.168     -0.517      0.606     -17.827      10.421\n",
      "x21          -11.1172      6.629     -1.677      0.095     -24.180       1.945\n",
      "x22           -3.7744      4.565     -0.827      0.409     -12.770       5.222\n",
      "x23          341.1803      6.703     50.903      0.000     327.973     354.388\n",
      "==============================================================================\n",
      "Omnibus:                       15.731   Durbin-Watson:                   2.245\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               26.742\n",
      "Skew:                          -0.364   Prob(JB):                     1.56e-06\n",
      "Kurtosis:                       4.427   Cond. No.                         92.1\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "0.9778634908124495\n",
      "0.9636790347154779\n",
      "801.0669116647829\n",
      "1352.272326363422\n"
     ]
    }
   ],
   "source": [
    "#importazione dei dati ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "from pandas import DataFrame\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy.linalg import toeplitz\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "df = pd.read_csv (r'/Users/patrickpinta/Desktop/1datasetpanda/soybean.csv',header=0,error_bad_lines=False) \n",
    "\n",
    "#modellazione dei dati training set------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "x= df.iloc[0:250,0:23]\n",
    "\n",
    "y= df.iloc[0:250,23:24]\n",
    "\n",
    "#modellazione dei dati test set------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "xcv=df.iloc[250:334,0:23]\n",
    "\n",
    "ycv= df.iloc[250:334,23:24]\n",
    "\n",
    "#stardadizzazione dei dati training set------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "x_train_stand=(scaler.fit_transform(x))\n",
    "\n",
    "#stardadizzazione dei dati test set------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "xcv_train_stand=(scaler.fit_transform(xcv))\n",
    "    \n",
    "#modello dati training set------------------------------------------------------------------------------------------------------------    \n",
    "    \n",
    "x_train_stand, y = np.array(x_train_stand), np.array(y)\n",
    "x_train_stand = sm.add_constant(x_train_stand)\n",
    "\n",
    "#modello dati training set------------------------------------------------------------------------------------------------------------    \n",
    "\n",
    "xcv_train_stand, ycv = np.array(xcv_train_stand), np.array(ycv)\n",
    "xcv_train_stand = sm.add_constant(xcv_train_stand)\n",
    "\n",
    "#procedura per sigma e per gls model ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "ols_resid = sm.OLS(y.astype(float), x_train_stand.astype(float)).fit().resid\n",
    "resid_fit = sm.OLS(ols_resid[1:], sm.add_constant(ols_resid[:-1])).fit()\n",
    "rho = resid_fit.params[1]\n",
    "toeplitz(range(5))\n",
    "order = toeplitz(range(len(ols_resid)))\n",
    "sigma = rho**order\n",
    "\n",
    "gls_model = sm.GLS(y, x_train_stand,sigma)\n",
    "gls_results = gls_model.fit()\n",
    "\n",
    "#print(gls_results.summary())\n",
    "\n",
    "#procedura per ols model ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "ols_model = sm.OLS(y, x_train_stand)\n",
    "ols_results = ols_model.fit() \n",
    "\n",
    "print(ols_results.summary())\n",
    "\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg= reg.fit(x_train_stand,y)\n",
    "\n",
    "#identify outliers ------------------------------------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "influence = ols_results.get_influence()\n",
    "\n",
    "cooks = influence.cooks_distance\n",
    "\n",
    "infl = influence.summary_frame().dfb_x1 > 2./250**.5\n",
    "\n",
    "print(influence.summary_frame()[infl].filter(regex=\"dfb_x1\"))\n",
    "\n",
    "print(2./417**.5)\n",
    "\n",
    "\"\"\"\n",
    "#forecast ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "ypredTrain = reg.predict(x_train_stand)\n",
    "ycvpred = reg.predict(xcv_train_stand)\n",
    "\n",
    "print(r2_score(y,ypredTrain))\n",
    "print(r2_score(ycv,ycvpred))\n",
    "print(mean_squared_error(y,ypredTrain))\n",
    "print(mean_squared_error(ycv,ycvpred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
